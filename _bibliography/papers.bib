---
---

@string{aps = {American Physical Society,}}


@article{seale2024evaluating,
  abbr={AAAI},
  bibtex_show={false},
  title={Evaluating Pre-Trial Programs Using Interpretable Machine Learning Matching Algorithms for Causal Inference},
  author={Jain, Saksham and Seale-Carlisle, Travis and Lee, Courtney and Levenson, Caroline and Ramprasad, Swathi and Garrett, Brandon and Roy, Sudeepa and Rudin, Cynthia and Volfovsky, Alexander},
  abstract={},
  journal={AAAI-24},
  year={2024},
  html={https://www.researchgate.net/publication/376406768_Evaluating_pre-trial_programs_using_interpretable_machine_learning_matching_algorithms_for_causal_inference?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InByb2ZpbGUiLCJwYWdlIjoicHJvZmlsZSJ9fQ},
  pdf={AAAI-24.pdf},
  poster={},
  slides={},
  google_scholar_id={jD0Xz3MAAAAJ},
  selected={true}
}

@article{kornfein2023closing,
  abbr={NeurIPS Workshop},
  title={Closing the domain gap: blended synthetic imagery for climate object detection},
  abstract={Accurate geospatial information about the causes and consequences of climate change, including energy systems infrastructure, is critical to planning climate change mitigation and adaptation strategies. When up-to-date spatial data on infrastructure is lacking, one approach to fill this gap is to learn from overhead imagery using deep-learning-based object detection algorithms. However, the performance of these algorithms can suffer when applied to diverse geographies, which is a common case. We propose a technique to generate realistic synthetic overhead images of an object (e.g., a generator) to enhance the ability of these techniques to transfer across diverse geographic domains. Our technique blends example objects into unlabeled images from the target domain using generative adversarial networks. This requires minimal labeled examples of the target object and is computationally efficient such that it can be used to generate a large corpus of synthetic imagery. We show that including these synthetic images in the training of an object detection model improves its ability to generalize to new domains (measured in terms of average precision) when compared to a baseline model and other relevant domain adaptation techniques.},
  author={Kornfein, Caleb and Willard, Frank and Tang, Caroline and Long, Yuxi and Jain, Saksham and Malof, Jordan and Ren, Simiao and Bradbury, Kyle},
  journal={Environmental Data Science},
  volume={2},
  pages={e39},
  year={2023},
  publisher={Cambridge University Press},
  html={https://www.cambridge.org/core/journals/environmental-data-science/article/closing-the-domain-gap-blended-synthetic-imagery-for-climate-object-detection/07CE35430B276340D7D3E047A95B4CC5},
  pdf={EDS.pdf},
  slides={https://slideslive.com/38994031},
  google_scholar_id={jD0Xz3MAAAAJ},
  selected={true}
}

@article{jain2022synthetic,
  bibtex_show={false},
  title={Synthetic data augmentation for surface defect detection and classification using deep learning},
  author={Jain, Saksham and Seth, Gautam and Paruthi, Arpit and Soni, Umang and Kumar, Girish},
  abstract = {Deep learning techniques, especially Convolutional Neural Networks (CNN), dominate the benchmarks for most computer vision tasks. These state-of-the-art results are typically obtained through supervised learning, for which large annotated datasets are required. However, acquiring such datasets for manufacturing applications remains a challenging proposition due to the time and costs involved in their collection. To overcome this disadvantage, a novel framework is proposed for data augmentation by creating synthetic images using Generative Adversarial Networks (GANs). The generator synthesizes new surface defect images from random noise which is trained over time to get realistic fakes. These synthetic images can be used further for training of classification algorithms. Three GAN architectures are trained, and the entire data augmentation pipeline is implemented for the Northeastern University (China) Classification (NEU-CLS) dataset for hot-rolled steel strips from NEU Surface Defect Database. The classification accuracy of a simple CNN architecture is measured on synthetic augmented data and further it is compared with similar state-of-the-arts. It is observed that the proposed GANs-based augmentation scheme significantly improves the performance of CNN for classification of surface defects. The classically augmented CNN yields sensitivity and specificity of 90.28% and 98.06% respectively. In contrast, the synthetically augmented CNN yields better results, with sensitivity and specificity of 95.33% and 99.16% respectively. Also, the use of GANs is demonstrated to disentangle the representation space and to add additional domain knowledge through synthetic augmentation that can be difficult to replicate through classic augmentation. The proposed framework demonstrates high generalization capability. It may be applied to other supervised surface inspection tasks, and thus facilitate the development of advanced vision-based inspection instruments for manufacturing applications.},
  journal={Journal of Intelligent Manufacturing},
  pages={1--14},
  year={2022},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s10845-020-01710-x},
  pdf={JIM.pdf},
  preview={jim.jpg},
  google_scholar_id={jD0Xz3MAAAAJ},
  selected={true}
}

@article{nayak2021mining,
  abbr={IEEE TPAMI},
  bibtex_show={false},
  title={Mining data impressions from deep models as substitute for the unavailable training data},
  author={Nayak, Gaurav Kumar and Mopuri, Konda Reddy and Jain, Saksham and Chakraborty, Anirban},
  abstract={Pretrained deep models hold their learnt knowledge in the form of model parameters. These parameters act as “memory” for the trained models and help them generalize well on unseen data. However, in absence of training data, the utility of a trained model is merely limited to either inference or better initialization towards a target task. In this paper, we go further and extract synthetic data by leveraging the learnt model parameters. We dub them Data Impressions , which act as proxy to the training data and can be used to realize a variety of tasks. These are useful in scenarios where only the pretrained models are available and the training data is not shared (e.g., due to privacy or sensitivity concerns). We show the applicability of data impressions in solving several computer vision tasks such as unsupervised domain adaptation, continual learning as well as knowledge distillation. We also study the adversarial robustness of lightweight models trained via knowledge distillation using these data impressions. Further, we demonstrate the efficacy of data impressions in generating data-free Universal Adversarial Perturbations (UAPs) with better fooling rates. Extensive experiments performed on benchmark datasets demonstrate competitive performance achieved using data impressions in absence of original training data.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={11},
  pages={8465--8481},
  year={2021},
  publisher={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/9540299},
  pdf={TPAMI.pdf},
  google_scholar_id={jD0Xz3MAAAAJ},
  selected={true}
}


@inproceedings{nayak2020fusion,
  bibtex_show={false},
  title={Fusion of Deep and Non-Deep Methods for Fast Super-Resolution of Satellite Images},
  author={Jain, Saksham and Nayak, Gaurav Kumar and Babu, R Venkatesh and Chakraborty, Anirban},
  abstract={In the emerging commercial space industry there is a drastic increase in access to low cost satellite imagery. The price for satellite images depends on the sensor quality and revisit rate. This work proposes to bridge the gap between image quality and the price by improving the image quality via super-resolution (SR). Recently, a number of deep SR techniques have been proposed to enhance satellite images. However, none of these methods utilize the region-level context information, giving equal importance to each region in the image. This, along with the fact that most state-of-the-art SR methods are complex and cumbersome deep models, the time taken to process very large satellite images can be impractically high. We, propose to handle this challenge by designing an SR framework that analyzes the regional information content on each patch of the low-resolution image and judiciously chooses to use more computationally complex deep models to super-resolve more structure-rich regions on the image, while using less resource-intensive non-deep methods on non-salient regions. Through extensive experiments on a large satellite image, we show substantial decrease in inference time while achieving similar performance to that of existing deep SR methods over several evaluation measures like PSNR, MSE and SSIM.},
  booktitle={2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)},
  pages={267--271},
  year={2020},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/9232612},
  pdf={BigMM.pdf},
  preview={bigmm.jpg},
  google_scholar_id={jD0Xz3MAAAAJ},
}

